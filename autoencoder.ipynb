{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoder.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/krapshsa/tensorflow-practice/blob/master/autoencoder.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "1kWQQWlCcap_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "19c39347-7316-416b-f117-f7907186ca85"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
        "\n",
        "\n",
        "# Training Parameters\n",
        "batch_size=256\n",
        "max_steps=1000\n",
        "display_steps=1000\n",
        "learning_rate=0.01\n",
        "\n",
        "\n",
        "# Network Parameters\n",
        "num_hidden_1 = 256 # 1st layer num features\n",
        "num_hidden_2 = 128 # 2nd layer num features (the latent dim)\n",
        "\n",
        "time_steps = 28\n",
        "feature_size = 28\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# tf Graph input (only pictures)\n",
        "'''\n",
        "[\n",
        "    [\n",
        "      [feature_1, feature_2, ... feature_n] # timestep_1\n",
        "      [feature_1, feature_2, ... feature_n] # timestep_2\n",
        "      ...\n",
        "      [feature_1, feature_2, ... feature_n] # timestep_n\n",
        "    ], #batch_1\n",
        "    ...\n",
        "]\n",
        "shape=(batches, steps, features)\n",
        "'''\n",
        "X = tf.placeholder(\"float\", [None, time_steps, feature_size])\n",
        "\n",
        "def autoencoder(x):\n",
        "  # Construct model\n",
        "  rnn_layers = [\n",
        "      tf.nn.rnn_cell.LSTMCell(\n",
        "        num_units=units,\n",
        "        forget_bias=1.0,\n",
        "        activation=tf.nn.tanh\n",
        "      ) for units in [num_hidden_1, num_hidden_2, num_hidden_1, feature_size]\n",
        "  ]\n",
        "\n",
        "  # create a RNN cell composed sequentially of a number of RNNCells\n",
        "  multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
        "  '''\n",
        "  [\n",
        "      [\n",
        "        [feature_1, feature_2, ... feature_n] # (batch_1 , timestep_1)\n",
        "        [feature_1, feature_2, ... feature_n] # (batch_2 , timestep_1)\n",
        "        ...\n",
        "        [feature_1, feature_2, ... feature_n] # (batch_n , timestep_1)\n",
        "      ],\n",
        "      ...\n",
        "  ]\n",
        "  shape=(steps, batches, features)\n",
        "  '''\n",
        "  inputs = tf.unstack(\n",
        "      value=x,\n",
        "      num=time_steps,\n",
        "      axis=1\n",
        "  )\n",
        "  outputs, states = tf.nn.static_rnn(\n",
        "      cell=multi_rnn_cell,\n",
        "      inputs=inputs,\n",
        "      dtype=tf.float32\n",
        "  )\n",
        "  \n",
        "  \n",
        "  '''\n",
        "  [\n",
        "      [\n",
        "        [feature_1, feature_2, ... feature_n] # (batch_1 , timestep_1)\n",
        "        [feature_1, feature_2, ... feature_n] # (batch_2 , timestep_1)\n",
        "        ...\n",
        "        [feature_1, feature_2, ... feature_n] # (batch_n , timestep_1)\n",
        "      ],\n",
        "      ...\n",
        "  ]\n",
        "  \n",
        "  shape=(steps, batches, features)\n",
        "  '''\n",
        "  return outputs\n",
        "\n",
        "# slice to keep only the last cell of the RNN\n",
        "\n",
        "outputs = autoencoder(X)\n",
        "'''\n",
        "[\n",
        "    [\n",
        "      [feature_1, feature_2, ... feature_n] # timestep_1\n",
        "      [feature_1, feature_2, ... feature_n] # timestep_2\n",
        "      ...\n",
        "      [feature_1, feature_2, ... feature_n] # timestep_n\n",
        "    ], #batch_1\n",
        "    ...\n",
        "]\n",
        "shape=(batches, steps, features)\n",
        "'''\n",
        "stack_outputs = tf.stack(\n",
        "    values=outputs,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Prediction\n",
        "y_pred = stack_outputs\n",
        "# Targets (Labels) are the input data.\n",
        "y_true = X\n",
        "\n",
        "print(tf.convert_to_tensor(outputs).get_shape())\n",
        "print(y_pred.get_shape())\n",
        "print(y_true.get_shape())\n",
        "\n",
        "# Define loss and optimizer, minimize the squared error\n",
        "loss = tf.reduce_mean(tf.square(tf.subtract(y_true, y_pred)))\n",
        "optimizer = tf.train.RMSPropOptimizer(learning_rate)\n",
        "train_op = optimizer.minimize(loss)\n",
        "\n",
        "# Initialize the variables (i.e. assign their default value)\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Start Training\n",
        "# Start a new TF session\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "\n",
        "    # Training\n",
        "    for i in range(1, max_steps+1):\n",
        "        # Prepare Data\n",
        "        # Get the next batch of MNIST data (only images are needed, not labels)\n",
        "        batch_x, _ = mnist.train.next_batch(batch_size)\n",
        "        sequence_x = batch_x.reshape((batch_size, time_steps, feature_size))\n",
        "\n",
        "        # Run optimization op (backprop) and cost op (to get loss value)\n",
        "        sess.run(train_op, feed_dict={X: sequence_x})"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "(28, ?, 28)\n",
            "(?, 28, 28)\n",
            "(?, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}